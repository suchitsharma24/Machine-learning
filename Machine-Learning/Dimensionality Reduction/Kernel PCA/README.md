## Kernel Principal Component Analysis 

In the field of multivariate statistics, kernel principal component analysis (kernel PCA) [1] is an extension of principal component analysis (PCA) using techniques of kernel methods. Using a kernel, the originally linear operations of PCA are performed in a reproducing kernel Hilbert space.

PCA is a linear method. That is it can only be applied to datasets which are linearly separable. It does an excellent job for datasets, which are linearly separable. But, if we use it to non-linear datasets, we might get a result which may not be the optimal dimensionality reduction. Kernel PCA uses a kernel function to project dataset into a higher dimensional feature space, where it is linearly separable. It is similar to the idea of Support Vector Machines.

**Case study:** To analyze Social Network dataset and fetch the best 2 independent/predictor variables which are highly correlated with the dependent variable and classify whether the user will click on the ad and buy the SUV. Use Kernel Principal Component Analysis model to solve this case study and finally calculate the accuracy of the model. 

Please find the dataset attached!

![alt text](https://github.com/prtk1306/MachineLearning/blob/master/ML%20Logo.PNG "Machine Learning")

Citation: https://www.udemy.com/, https://en.wikipedia.org/, https://www.geeksforgeeks.org/